from transformers import AutoTokenizer
import json
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np


def preprocess_with_chat_template():
    """
    LLM íŒŒì¸íŠœë‹ì„ ìœ„í•œ ëŒ€í™” ë°ì´í„° ì „ì²˜ë¦¬ ë°©ë²•ì„ ì‹œì—°í•©ë‹ˆë‹¤.
    chat_templateì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” í„´ì„ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    model_name = "meta-llama/Llama-3.2-1B-Instruct"
    print(f"â³ {model_name}ì˜ chat_templateì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤...")

    # ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„± (ì‹¤ì œë¡œëŠ” ì™¸ë¶€ íŒŒì¼ì—ì„œ ë¡œë“œí•  ìˆ˜ ìˆìŒ)
    sample_conversations = [
        {
            "messages": [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.",
                },
                {"role": "user", "content": "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ íŒŒì¸íŠœë‹ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"},
                {
                    "role": "assistant",
                    "content": "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ íŒŒì¸íŠœë‹ì€ ì‚¬ì „ í•™ìŠµëœ ëŒ€ê·œëª¨ ëª¨ë¸ì„ íŠ¹ì • ì‘ì—…ì´ë‚˜ ë„ë©”ì¸ì— ë§ê²Œ ì¡°ì •í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì „ì²´ ëª¨ë¸ì„ ì²˜ìŒë¶€í„° í•™ìŠµì‹œí‚¤ëŠ” ê²ƒë³´ë‹¤ íš¨ìœ¨ì ì´ë©°, ì ì€ ì–‘ì˜ ë°ì´í„°ë¡œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                },
            ]
        },
        {
            "messages": [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.",
                },
                {
                    "role": "user",
                    "content": "íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                },
                {
                    "role": "assistant",
                    "content": "íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì£¼ìš” ì°¨ì´ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: 1) ê°€ë³€ì„±: ë¦¬ìŠ¤íŠ¸ëŠ” ê°€ë³€(mutable)ì´ê³  íŠœí”Œì€ ë¶ˆë³€(immutable)ì…ë‹ˆë‹¤. 2) ë¬¸ë²•: ë¦¬ìŠ¤íŠ¸ëŠ” ëŒ€ê´„í˜¸ [], íŠœí”Œì€ ì†Œê´„í˜¸ ()ë¡œ ì •ì˜í•©ë‹ˆë‹¤. 3) ì‚¬ìš© ìš©ë„: ë¦¬ìŠ¤íŠ¸ëŠ” ë™ì¼í•œ ìœ í˜•ì˜ í•­ëª© ì»¬ë ‰ì…˜ì— ì í•©í•˜ê³ , íŠœí”Œì€ ê´€ë ¨ëœ ë‹¤ë¥¸ ìœ í˜•ì˜ í•­ëª©ì„ ê·¸ë£¹í™”í•˜ëŠ” ë° ì í•©í•©ë‹ˆë‹¤.",
                },
            ]
        },
    ]

    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(model_name)

    # í† í¬ë‚˜ì´ì €ì˜ chat_template í™•ì¸
    print("\nğŸ“ í† í¬ë‚˜ì´ì €ì˜ chat_template:")
    if hasattr(tokenizer, "chat_template") and tokenizer.chat_template:
        print(tokenizer.chat_template)
    else:
        print(
            "  - ì´ í† í¬ë‚˜ì´ì €ì—ëŠ” ê¸°ë³¸ chat_templateì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ì •ì˜ í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
        )
        # ì‚¬ìš©ì ì •ì˜ í…œí”Œë¦¿ ì •ì˜
        tokenizer.chat_template = "{% for message in messages %}\n{% if message['role'] == 'system' %}<|system|>\n{{ message['content'] }}\n{% elif message['role'] == 'user' %}<|user|>\n{{ message['content'] }}\n{% elif message['role'] == 'assistant' %}<|assistant|>\n{{ message['content'] }}\n{% endif %}\n{% endfor %}"
        print(f"  - ì‚¬ìš©ì ì •ì˜ í…œí”Œë¦¿:\n{tokenizer.chat_template}")

    print("\nğŸ”„ ëŒ€í™” ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê³  í† í°í™”í•©ë‹ˆë‹¤...")

    # ëŒ€í™”ë¥¼ chat_template í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ë° í† í°í™”
    processed_samples = []
    token_lengths = []

    for i, conversation in enumerate(sample_conversations):
        # 1. chat_template ì ìš©
        formatted_chat = tokenizer.apply_chat_template(
            conversation["messages"], tokenize=False, add_generation_prompt=True
        )

        # 2. í† í°í™”
        tokenized_chat = tokenizer.encode(formatted_chat)
        token_lengths.append(len(tokenized_chat))

        # ì˜ˆì‹œ ì¶œë ¥
        print(f"\nğŸ“Š ëŒ€í™” {i+1} ì²˜ë¦¬ ê²°ê³¼:")
        print(f"  - ì›ë³¸ ë©”ì‹œì§€ ìˆ˜: {len(conversation['messages'])}")
        print(f"  - í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(formatted_chat)} ë¬¸ì")
        print(f"  - í† í° ìˆ˜: {len(tokenized_chat)}")

        # ì²˜ìŒ ëª‡ ì¤„ë§Œ ì¶œë ¥
        formatted_lines = formatted_chat.split("\n")
        preview_lines = (
            "\n".join(formatted_lines[:6]) + "\n..."
            if len(formatted_lines) > 6
            else formatted_chat
        )
        print(f"\nğŸ” í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°:\n{preview_lines}")

        # ì¼ë¶€ í† í° IDì™€ í•´ë‹¹ í† í° ì¶œë ¥
        print("\nğŸ”¤ í† í°í™” ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 10ê°œ):")
        tokens = tokenizer.convert_ids_to_tokens(tokenized_chat[:10])
        for token_id, token in zip(tokenized_chat[:10], tokens):
            print(f"  - ID {token_id}: '{token}'")

        # ê²°ê³¼ ì €ì¥
        processed_samples.append(
            {
                "ëŒ€í™” ID": i + 1,
                "ì›ë³¸ ëŒ€í™”": conversation,
                "í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸": formatted_chat,
                "í† í°í™”ëœ ID": tokenized_chat,
                "í† í° ìˆ˜": len(tokenized_chat),
            }
        )

    # í† í° ê¸¸ì´ í†µê³„ ê³„ì‚°
    avg_tokens = np.mean(token_lengths)
    max_tokens = np.max(token_lengths)
    min_tokens = np.min(token_lengths)

    print(f"\nğŸ“Š í† í° ê¸¸ì´ í†µê³„:")
    print(f"  - í‰ê·  í† í° ìˆ˜: {avg_tokens:.1f}")
    print(f"  - ìµœëŒ€ í† í° ìˆ˜: {max_tokens}")
    print(f"  - ìµœì†Œ í† í° ìˆ˜: {min_tokens}")

    # ë°ì´í„° ì €ì¥
    with open("processed_conversations.json", "w", encoding="utf-8") as f:
        json.dump(processed_samples, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ processed_conversations.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ìƒ˜í”Œ í›ˆë ¨ ë°ì´í„°ì…‹ í˜•ì‹ ì„¤ëª…
    print("\nğŸ“š íŒŒì¸íŠœë‹ì„ ìœ„í•œ ë°ì´í„°ì…‹ êµ¬ì¡°í™” ë°©ë²•:")
    print("  1. í† í°í™”ëœ IDë¥¼ ì…ë ¥ ë° ë ˆì´ë¸”ë¡œ ë¶„ë¦¬ (ë§ˆìŠ¤í‚¹)")
    print("  2. attention_mask ìƒì„± (íŒ¨ë”© í† í° ìœ„ì¹˜ í‘œì‹œ)")
    print("  3. ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒ¨ë”© ì¶”ê°€")
    print("  4. DataLoaderë¥¼ í†µí•œ ë¯¸ë‹ˆë°°ì¹˜ êµ¬ì„±")

    # íŒŒì¸íŠœë‹ì„ ìœ„í•œ ë°ì´í„° êµ¬ì„± ì˜ˆì‹œ
    print("\nğŸ§© íŒŒì¸íŠœë‹ ë°ì´í„°ì…‹ ì˜ˆì‹œ í˜•ì‹:")
    print(
        """  {
    "input_ids": [1, 2, 3, 4, 5, ...],       # í† í°í™”ëœ ì…ë ¥ ID
    "attention_mask": [1, 1, 1, 1, 1, ...],  # íŒ¨ë”©ì´ ì•„ë‹Œ ìœ„ì¹˜ëŠ” 1, íŒ¨ë”©ì€ 0
    "labels": [1, 2, 3, 4, 5, ...]           # ë‹¤ìŒ í† í° ì˜ˆì¸¡ì„ ìœ„í•œ ë ˆì´ë¸”
  }"""
    )


if __name__ == "__main__":
    preprocess_with_chat_template()
