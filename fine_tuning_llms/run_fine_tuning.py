#!/usr/bin/env python3
import argparse
import subprocess
import os


def print_header(message):
    """í—¤ë” í˜•ì‹ìœ¼ë¡œ ë©”ì‹œì§€ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print(f" {message}")
    print("=" * 80)


def run_command(command, description):
    """ëª…ë ¹ì–´ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥"""
    print_header(description)
    print(f"ì‹¤í–‰ ëª…ë ¹ì–´: {command}")
    print("-" * 80)
    result = subprocess.run(command, shell=True, text=True)
    return result.returncode == 0


def main():
    parser = argparse.ArgumentParser(description="LLM íŒŒì¸íŠœë‹ ì‹¤ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument(
        "--task",
        type=str,
        default="all",
        choices=["compare", "special_tokens", "preprocess", "train", "explain", "all"],
        help="ì‹¤í–‰í•  ì‘ì—… ì„ íƒ (ê¸°ë³¸ê°’: all)",
    )
    parser.add_argument(
        "--model",
        type=str,
        default="meta-llama/Llama-3.2-1B-Instruct",
        help="íŒŒì¸íŠœë‹ì— ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸ê°’: meta-llama/Llama-3.2-1B-Instruct)",
    )
    parser.add_argument(
        "--dataset",
        type=str,
        default=None,
        help="HuggingFace ë°ì´í„°ì…‹ ì´ë¦„ (ê¸°ë³¸ê°’: ìƒ˜í”Œ ë°ì´í„°ì…‹ ì‚¬ìš©)",
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./results",
        help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: ./results)",
    )
    parser.add_argument(
        "--epochs", type=int, default=1, help="í•™ìŠµ ì—í¬í¬ ìˆ˜ (ê¸°ë³¸ê°’: 1)"
    )
    parser.add_argument(
        "--batch_size", type=int, default=1, help="ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 1)"
    )
    parser.add_argument("--lr", type=float, default=2e-5, help="í•™ìŠµë¥  (ê¸°ë³¸ê°’: 2e-5)")
    parser.add_argument("--lora_r", type=int, default=8, help="LoRA ë­í¬ (ê¸°ë³¸ê°’: 8)")
    parser.add_argument("--load_8bit", action="store_true", help="8ë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©")
    parser.add_argument(
        "--dataset_path", type=str, default=None, help="ë¡œì»¬ ë°ì´í„°ì…‹ ê²½ë¡œ"
    )

    args = parser.parse_args()

    print_header("ğŸŒŸ LLaMA ëª¨ë¸ íŒŒì¸íŠœë‹ ì‹¤ìŠµ ì‹œì‘ ğŸŒŸ")

    # ì‘ì—… ëª©ë¡ ê²°ì •
    tasks = []
    if args.task == "all":
        tasks = ["compare", "special_tokens", "preprocess", "explain", "train"]
    else:
        tasks = [args.task]

    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)

    for task in tasks:
        if task == "compare":
            # ëª¨ë¸ ë¹„êµ ì‹¤í–‰
            run_command(
                "python model_comparison.py", "ë² ì´ìŠ¤ ëª¨ë¸ê³¼ ì¸ìŠ¤íŠ¸ëŸ­íŠ¸ ëª¨ë¸ ë¹„êµ"
            )

        elif task == "special_tokens":
            # ìŠ¤í˜ì…œ í† í° íƒìƒ‰ ì‹¤í–‰
            run_command("python special_tokens.py", "LLM ìŠ¤í˜ì…œ í† í° íƒìƒ‰")

        elif task == "preprocess":
            # ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰
            run_command(
                "python data_preprocessing.py",
                "chat_templateì„ ì‚¬ìš©í•œ ëŒ€í™” ë°ì´í„° ì „ì²˜ë¦¬",
            )

        elif task == "explain":
            # Trainer ì„¤ëª… ì‹¤í–‰
            run_command("python trainer_explained.py", "Trainer í´ë˜ìŠ¤ ë™ì‘ ì›ë¦¬ ì„¤ëª…")

        elif task == "train":
            # íŒŒì¸íŠœë‹ ì‹¤í–‰
            command = f"python fine_tuning.py "
            command += f"--model_name {args.model} "
            command += f"--output_dir {args.output_dir} "
            command += f"--num_train_epochs {args.epochs} "
            command += f"--per_device_train_batch_size {args.batch_size} "
            command += f"--learning_rate {args.lr} "
            command += f"--lora_r {args.lora_r} "

            if args.load_8bit:
                command += "--load_in_8bit "

            if args.dataset:
                command += f"--dataset_name {args.dataset} "

            if args.dataset_path:
                command += f"--dataset_path {args.dataset_path} "

            run_command(command, "PEFTë¥¼ ì‚¬ìš©í•œ LLaMA ëª¨ë¸ íŒŒì¸íŠœë‹")

    print_header("ğŸ‰ LLM íŒŒì¸íŠœë‹ ì‹¤ìŠµì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("\nì‹¤í–‰ëœ ì‘ì—…:")
    for i, task in enumerate(tasks):
        print(f"  {i+1}. {task}")

    print("\nê²°ê³¼ë¬¼ í™•ì¸ ë°©ë²•:")
    print(f"  - ëª¨ë¸ ë¹„êµ ê²°ê³¼: model_comparison_results.csv")
    print(f"  - ìŠ¤í˜ì…œ í† í° ë¶„ì„: special_tokens_analysis.csv")
    print(f"  - ì „ì²˜ë¦¬ëœ ëŒ€í™” ë°ì´í„°: processed_conversations.json")
    print(f"  - íŒŒì¸íŠœë‹ëœ ëª¨ë¸: {args.output_dir}/final_model/")


if __name__ == "__main__":
    main()
